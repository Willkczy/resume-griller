# Interview Coach - AI-Powered Mock Interview System

An LLM-based application that generates contextual interview questions based on uploaded resumes. Built with LoRA fine-tuning and RAG pipeline.

##  Architecture
```
PDF Upload â†’ Resume Parser â†’ Chunker â†’ Embedder â†’ Retriever â†’ Fine-tuned LLM â†’ Questions
```

## ğŸ“ Project Structure
```
interview-coach/
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ resume_parser.py    # PDF/text parsing
â”‚   â”œâ”€â”€ chunker.py          # Semantic chunking
â”‚   â”œâ”€â”€ embedder.py         # Vector embeddings (ChromaDB)
â”‚   â”œâ”€â”€ retriever.py        # RAG retrieval
â”‚   â””â”€â”€ generator.py        # LLM question generation
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_resumes/     # Test resumes
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_parser.py
â”œâ”€â”€ export_prompts.py       # Export prompts for Colab inference
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

##  Quick Start

### Installation
```bash
conda create -n interview-coach python=3.11
conda activate interview-coach
pip install -r requirements.txt
```

### Run RAG Pipeline
```bash
# Test parser
python -m rag.resume_parser

# Test full pipeline
python -m rag.retriever

# Export prompts for Colab
python export_prompts.py
```

### Model Inference (Colab)

Model hosted on HuggingFace: [shubhampareek/interview-coach-lora](https://huggingface.co/shubhampareek/interview-coach-lora)

Use `Interview_Coach_Inference.ipynb` for GPU-accelerated inference.

##  Tech Stack

- **Fine-tuning:** LoRA on Mistral-7B
- **Embeddings:** sentence-transformers (all-MiniLM-L6-v2)
- **Vector DB:** ChromaDB
- **Framework:** PyTorch, Transformers, PEFT


##  License

MIT