# ğŸ”¥ Resume Griller

AI-powered interview simulator that "grills" candidates with deep, resume-specific questions.

## ğŸ¯ What We're Building

An application that:
1. **Parses resumes** (PDF/DOCX) and extracts structured information
2. **Generates targeted interview questions** based on resume content
3. **Conducts mock interviews** with voice interaction and video feed
4. **"Grills" candidates** by asking follow-up questions when answers are vague

### Two Interview Modes
- **HR Mode**: Behavioral questions, STAR method deep-dives
- **Tech Mode**: Technical verification, system design, implementation details

---

## ğŸ“ Project Structure

```
resume-griller/
â”‚
â”œâ”€â”€ backend/                    # FastAPI backend (Python)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routes/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/              # Core business logic
â”‚   â”‚   â”‚   â””â”€â”€ resume_parser.py   # â­ PDF/DOCX parsing
â”‚   â”‚   â”œâ”€â”€ services/          # External service integrations
â”‚   â”‚   â”‚   â””â”€â”€ llm_service.py     # LLM abstraction (API + Local)
â”‚   â”‚   â”œâ”€â”€ models/            # Pydantic schemas
â”‚   â”‚   â””â”€â”€ db/                # Database
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ ml/                         # Machine Learning module
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ resumes/           # Resume datasets
â”‚   â”‚   â”œâ”€â”€ interview_qa/      # Interview Q&A datasets
â”‚   â”‚   â””â”€â”€ processed/         # Processed training data
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ checkpoints/       # Training checkpoints
â”‚   â”‚   â””â”€â”€ exported/          # Exported models for inference
â”‚   â”œâ”€â”€ training/              # LoRA fine-tuning scripts
â”‚   â”œâ”€â”€ evaluation/            # Model evaluation & benchmarks
â”‚   â””â”€â”€ configs/               # Training configurations
â”‚
â”œâ”€â”€ frontend/                   # Next.js frontend (TypeScript)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/               # Pages
â”‚       â”œâ”€â”€ components/        # React components
â”‚       â””â”€â”€ hooks/             # Custom hooks
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ pyproject.toml             # Python dependencies (using uv)
â””â”€â”€ .env.example               # Environment variables template
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- [uv](https://github.com/astral-sh/uv) (Python package manager)
- Node.js 18+ (for frontend)

### 1. Clone & Setup

```bash
git clone https://github.com/YOUR_USERNAME/resume-griller.git
cd resume-griller

# Copy environment template
cp .env.example .env
# Edit .env with your API keys
```

### 2. Backend Setup (using uv)

```bash
# Install uv if you haven't
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
uv pip install -e ".[dev]"

# For ML work, also install ML dependencies
uv pip install -e ".[ml]"

# Run the backend
cd backend
uvicorn app.main:app --reload --port 8000
```

### 3. Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ‘¥ Team Responsibilities

| Area | Owner | Key Files |
|------|-------|-----------|
| PDF Parser | TBD | `backend/app/core/resume_parser.py` |
| LoRA Fine-tuning | TBD | `ml/training/`, `ml/data/` |
| Frontend | TBD | `frontend/src/` |
| Interview Agent | TBD | `backend/app/core/interview_agent.py` |

---

## ğŸ”§ Architecture Decisions

### LLM Strategy: API vs Fine-tuned Model

We support **both approaches** and can switch between them:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM Service Abstraction            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚  API Mode   â”‚      â”‚    Local Mode       â”‚ â”‚
â”‚   â”‚             â”‚      â”‚                     â”‚ â”‚
â”‚   â”‚ Claude API  â”‚      â”‚  Fine-tuned Model   â”‚ â”‚
â”‚   â”‚ GPT-4o API  â”‚      â”‚  (LoRA on Llama/    â”‚ â”‚
â”‚   â”‚             â”‚      â”‚   Mistral/etc)      â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                       â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚                          â”‚
â”‚            Unified Interface                   â”‚
â”‚                     â”‚                          â”‚
â”‚              Interview Agent                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration** (in `.env`):
```bash
LLM_MODE=api          # "api" or "local"
LLM_PROVIDER=anthropic  # "anthropic" or "openai" (when mode=api)
LOCAL_MODEL_PATH=./ml/models/exported/resume-griller  # (when mode=local)
```

### Why This Design?
1. **Flexibility**: Easy to compare API vs fine-tuned model performance
2. **Cost optimization**: Use local model for high-volume, API for complex tasks
3. **Independent development**: ML team can work on fine-tuning while others use API

---

## ğŸ“‹ Development Phases

### Phase 1: Core MVP (Current)
- [ ] Resume PDF/DOCX parsing
- [ ] Basic question generation (using API)
- [ ] Text-based Q&A interface
- [ ] Grilling logic (follow-up detection)

### Phase 2: Voice Integration
- [ ] Speech-to-Text (Deepgram)
- [ ] Text-to-Speech (ElevenLabs)
- [ ] Real-time audio streaming

### Phase 3: Video & Polish
- [ ] WebRTC video feed
- [ ] HR/Tech mode switching
- [ ] UI/UX improvements

### Phase 4: ML Integration
- [ ] LoRA fine-tuning pipeline
- [ ] Model evaluation & benchmarking
- [ ] Hybrid API + Local strategy

---

## ğŸ”€ Git Workflow

### Branching

```
main
  â””â”€â”€ feature/your-feature-name
```

### Branch Naming
```
feature/pdf-parser
feature/lora-training
feature/interview-agent
fix/resume-encoding
```

### Commit Messages
```
feat(parser): add PDF text extraction
feat(ml): setup LoRA training pipeline
fix(api): handle timeout errors
docs(readme): update setup instructions
```

### Pull Request Process
1. Create feature branch from `main`
2. Make your changes
3. Push and create PR
4. Get at least 1 review
5. Squash and merge

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI, Python 3.11 |
| Frontend | Next.js 14, React, TypeScript |
| Package Manager | uv (Python), npm (Node.js) |
| LLM (API) | Claude 3.5 / GPT-4o |
| LLM (Local) | Llama 3 / Mistral + LoRA |
| STT | Deepgram |
| TTS | ElevenLabs |
| Database | SQLite (dev), PostgreSQL (prod) |

---

## ğŸ“š Useful Resources

### For PDF Parsing
- [PyMuPDF Documentation](https://pymupdf.readthedocs.io/)
- [pdfplumber Documentation](https://github.com/jsvine/pdfplumber)

### For LoRA Fine-tuning
- [PEFT Documentation](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [Fine-tuning LLMs Guide](https://huggingface.co/docs/transformers/training)

### Resume Datasets
- [Resume Dataset (Kaggle)](https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset)
- [Resume Corpus](https://github.com/florex/resume_corpus)

---

## â“ Questions?

Open an issue or reach out to the team!
